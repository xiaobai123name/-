"""
è‹æ ¼æ‹‰åº•å¯¹è¯å¼•æ“
é€šè¿‡å¼•å¯¼å¼æé—®å¸®åŠ©ç”¨æˆ·æ·±å…¥æ€è€ƒå’Œè‡ªä¸»å‘ç°ç­”æ¡ˆ
"""

import json
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

from ..config import settings
from ..retrieval.vector_store import VectorStore
from ..retrieval.hybrid_retriever import HybridRetriever
from ..database.crud import DatabaseManager
from ..llm.router import ModelRouter
from ..rag.prompts import PromptTemplates


class DialoguePhase(Enum):
    """å¯¹è¯é˜¶æ®µ"""
    EXPLORATION = "exploration"      # æ¢ç´¢é˜¶æ®µï¼šäº†è§£å­¦ç”Ÿè®¤çŸ¥æ°´å¹³
    CLARIFICATION = "clarification"  # æ¾„æ¸…é˜¶æ®µï¼šå¸®åŠ©æ˜ç¡®æ¦‚å¿µ
    DEEPENING = "deepening"          # æ·±å…¥é˜¶æ®µï¼šæŒ‘æˆ˜å‡è®¾
    SYNTHESIS = "synthesis"          # ç»¼åˆé˜¶æ®µï¼šå¼•å¯¼å½’çº³ç»“è®º
    COMPLETION = "completion"        # å®Œæˆé˜¶æ®µï¼šæ€»ç»“ç¡®è®¤


@dataclass
class SocraticResponse:
    """è‹æ ¼æ‹‰åº•å¼å›å¤"""
    question: str                    # å¼•å¯¼æ€§é—®é¢˜
    hint: Optional[str]              # æç¤ºï¼ˆå¯é€‰ï¼‰
    phase: DialoguePhase             # å½“å‰é˜¶æ®µ
    encouragement: Optional[str]     # é¼“åŠ±è¯­ï¼ˆå¯é€‰ï¼‰
    knowledge_check: bool            # æ˜¯å¦ä¸ºçŸ¥è¯†æ£€éªŒé—®é¢˜
    related_concepts: List[str]      # ç›¸å…³æ¦‚å¿µ
    progress: float                  # ç†è§£è¿›åº¦ (0-1)


class SocraticEngine:
    """è‹æ ¼æ‹‰åº•å¯¹è¯å¼•æ“"""
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½é‡‡ç”¨è‹æ ¼æ‹‰åº•æ•™å­¦æ³•çš„æ™ºæ…§å¯¼å¸ˆã€‚ä½ çš„æ ¸å¿ƒåŸåˆ™æ˜¯ï¼šæ°¸è¿œä¸è¦ç›´æ¥ç»™å‡ºç­”æ¡ˆï¼Œè€Œæ˜¯é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„é—®é¢˜å¼•å¯¼å­¦ç”Ÿè‡ªå·±å‘ç°ç­”æ¡ˆã€‚

## æ•™å­¦ç­–ç•¥

### å¯¹è¯é˜¶æ®µï¼ˆæ ¹æ®è½®æ¬¡è‡ªåŠ¨è°ƒæ•´ï¼‰ï¼š
- **ç¬¬1-2è½®ï¼ˆæ¢ç´¢ï¼‰**ï¼šæå‡ºå¼€æ”¾æ€§é—®é¢˜ï¼Œäº†è§£å­¦ç”Ÿçš„å·²æœ‰è®¤çŸ¥
- **ç¬¬3-4è½®ï¼ˆæ¾„æ¸…ï¼‰**ï¼šé’ˆå¯¹å­¦ç”Ÿçš„å›ç­”ï¼Œè¿½é—®ä»¥å¸®åŠ©æ˜ç¡®æ¦‚å¿µ
- **ç¬¬5-6è½®ï¼ˆæ·±å…¥ï¼‰**ï¼šæå‡ºæ›´æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ï¼ŒæŒ‘æˆ˜å­¦ç”Ÿçš„å‡è®¾
- **ç¬¬7è½®ä»¥åï¼ˆç»¼åˆï¼‰**ï¼šå¼•å¯¼å­¦ç”Ÿè‡ªå·±å½’çº³æ€»ç»“

### å›å¤è§„åˆ™ï¼š
1. **æ°¸è¿œä»¥é—®é¢˜ç»“å°¾**ï¼šæ¯æ¬¡å›å¤å¿…é¡»ä»¥ä¸€ä¸ªå¼•å¯¼æ€§é—®é¢˜ç»“æŸ
2. **ç®€çŸ­é¼“åŠ±**ï¼šå¯¹å­¦ç”Ÿçš„æ€è€ƒç»™äºˆç®€çŸ­è‚¯å®š
3. **ç±»æ¯”å¼•å¯¼**ï¼šé€‚å½“ä½¿ç”¨ç±»æ¯”å¸®åŠ©ç†è§£æŠ½è±¡æ¦‚å¿µ
4. **æç¤ºè€Œéç­”æ¡ˆ**ï¼šå¦‚æœå­¦ç”Ÿå¤šæ¬¡å›°æƒ‘ï¼Œç»™å‡ºå°æç¤ºä½†ä»ä»¥é—®é¢˜å‘ˆç°

### è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
```json
{{
  "encouragement": "å¯¹å­¦ç”Ÿå›ç­”çš„ç®€çŸ­è‚¯å®šï¼ˆå¯é€‰ï¼Œå¦‚æœå­¦ç”Ÿå›ç­”æœ‰é“ç†ï¼‰",
  "bridge": "è¿‡æ¸¡æ€§çš„æ€è€ƒå¼•å¯¼ï¼ˆ1-2å¥è¯ï¼‰",
  "question": "å¼•å¯¼æ€§é—®é¢˜ï¼ˆå¿…é¡»ï¼‰",
  "hint": "å¦‚æœå­¦ç”Ÿå¤šæ¬¡å›°æƒ‘æ—¶çš„å°æç¤ºï¼ˆå¯é€‰ï¼‰",
  "phase": "å½“å‰é˜¶æ®µï¼šexploration/clarification/deepening/synthesis",
  "progress": 0.0åˆ°1.0ä¹‹é—´çš„æ•°å­—ï¼Œè¡¨ç¤ºå­¦ç”Ÿå¯¹è¯¥ä¸»é¢˜çš„ç†è§£è¿›åº¦
}}
```

### å‚è€ƒèµ„æ–™ï¼ˆåŸºäºç”¨æˆ·æ–‡æ¡£ï¼‰ï¼š
{context}

è¯·å§‹ç»ˆç”¨ä¸­æ–‡å›å¤ã€‚"""

    USER_PROMPT = """å¯¹è¯å†å²ï¼š
{history}

å­¦ç”Ÿæœ€æ–°çš„é—®é¢˜/å›ç­”ï¼š
{input}

å½“å‰æ˜¯ç¬¬ {turn} è½®å¯¹è¯ã€‚

è¯·æ ¹æ®è‹æ ¼æ‹‰åº•æ•™å­¦æ³•ï¼Œç”Ÿæˆå¼•å¯¼æ€§å›å¤ã€‚è®°ä½ï¼š
1. ä¸è¦ç›´æ¥å›ç­”é—®é¢˜
2. ç”¨é—®é¢˜å¼•å¯¼å­¦ç”Ÿæ€è€ƒ
3. è¾“å‡ºä¸¥æ ¼çš„JSONæ ¼å¼"""

    def __init__(
        self,
        vector_store: VectorStore,
        db_manager: DatabaseManager,
        api_key: Optional[str] = None
    ):
        """åˆå§‹åŒ–è‹æ ¼æ‹‰åº•å¼•æ“"""
        self.vector_store = vector_store
        self.db = db_manager
        self.retriever = HybridRetriever(vector_store)
        # æ¨¡å‹è·¯ç”±ï¼šæŒ‰ç”¨æˆ·+æ¨¡å—åŠ¨æ€é€‰æ‹© provider/model
        self.model_router = ModelRouter(db_manager)
    
    def _coerce_content_to_text(self, content: Any) -> str:
        """
        å°† LangChain è¿”å›çš„ message.content å½’ä¸€åŒ–ä¸ºå­—ç¬¦ä¸²ã€‚

        è¯´æ˜ï¼šéƒ¨åˆ† provider/ç‰ˆæœ¬å¯èƒ½è¿”å› list[dict] çš„å¤šæ¨¡æ€ç»“æ„ï¼ˆä¾‹å¦‚ [{"type":"text","text":"..."}]ï¼‰ã€‚
        """
        if content is None:
            return ""
        if isinstance(content, str):
            return content
        if isinstance(content, (bytes, bytearray)):
            try:
                return content.decode("utf-8", errors="ignore")
            except Exception:
                return ""
        if isinstance(content, list):
            parts: List[str] = []
            for p in content:
                if isinstance(p, str):
                    parts.append(p)
                    continue
                if isinstance(p, dict):
                    # å¸¸è§ç»“æ„ï¼š{"type":"text","text":"..."}
                    txt = p.get("text") or p.get("content") or ""
                    if isinstance(txt, str) and txt:
                        parts.append(txt)
            return "\n".join([t for t in parts if t]).strip()
        # å…œåº•ï¼šè½¬å­—ç¬¦ä¸²
        try:
            return str(content)
        except Exception:
            return ""

    def _parse_response(self, response: str) -> Dict:
        """è§£æLLMçš„JSONå“åº”"""
        text = self._coerce_content_to_text(response).strip()
        if not text:
            return {"question": "ä½ æ„¿æ„å…ˆè¯´è¯´ä½ ç›®å‰çš„ç†è§£å—ï¼Ÿ", "phase": "exploration", "progress": 0.3}

        # 1) ä¼˜å…ˆæå– code-fence å†…çš„ JSONï¼ˆå…¼å®¹ ```json / ```ï¼‰
        json_match = re.search(r"```(?:json)?\s*([\s\S]*?)\s*```", text, flags=re.IGNORECASE)
        json_str = (json_match.group(1) if json_match else text).strip()

        # å…¼å®¹ï¼šåªæœ‰å¼€å¤´ ```json ä½†æ²¡æœ‰é—­åˆ ``` çš„æƒ…å†µ
        if not json_match and json_str.lstrip().startswith("```"):
            nl = json_str.find("\n")
            if nl != -1:
                json_str = json_str[nl + 1 :].strip()
            json_str = re.sub(r"\s*```+\s*$", "", json_str).strip()

        # 2) ä¿®å¤å¸¸è§ trailing commas
        json_str = re.sub(r",\s*}", "}", json_str)
        json_str = re.sub(r",\s*]", "]", json_str)

        # 3) å°è¯•ä¸¥æ ¼ json.loads
        try:
            obj = json.loads(json_str)
            return obj if isinstance(obj, dict) else {"question": text, "phase": "exploration", "progress": 0.3}
        except Exception:
            pass

        # 4) å…œåº•ï¼šraw_decode è§£æç¬¬ä¸€ä¸ª JSON å¯¹è±¡ï¼Œå¿½ç•¥åç»­å™ªå£°
        try:
            # ä»ç¬¬ä¸€ä¸ª { å¼€å§‹
            start = json_str.find("{")
            if start >= 0:
                decoder = json.JSONDecoder()
                obj, _end = decoder.raw_decode(json_str[start:])
                if isinstance(obj, dict):
                    return obj
        except Exception:
            pass

        # 5) æœ€ç»ˆå…œåº•ï¼šæŠŠæ•´æ®µæ–‡æœ¬å½“ä½œ question
        return {"question": text, "phase": "exploration", "progress": 0.3}
    
    def _format_history(self, messages: List[Dict]) -> str:
        """æ ¼å¼åŒ–å¯¹è¯å†å²"""
        if not messages:
            return "ï¼ˆè¿™æ˜¯å¯¹è¯çš„å¼€å§‹ï¼‰"
        
        history_parts = []
        for msg in messages[-6:]:  # åªä¿ç•™æœ€è¿‘6è½®
            role_raw = (msg.get("role") or "").strip().lower()
            role = "å­¦ç”Ÿ" if role_raw == "user" else "å¯¼å¸ˆ"
            content = (msg.get("content") or "").strip()
            if not content:
                continue
            history_parts.append(f"{role}ï¼š{content}")
        
        return "\n".join(history_parts)
    
    def respond(
        self,
        user_input: str,
        user_id: str,
        conversation_history: List[Dict],
        document_ids: Optional[List[str]] = None
    ) -> SocraticResponse:
        """
        ç”Ÿæˆè‹æ ¼æ‹‰åº•å¼å›å¤
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            user_id: ç”¨æˆ·ID
            conversation_history: å¯¹è¯å†å²
            document_ids: é™å®šæ–‡æ¡£èŒƒå›´
            
        Returns:
            SocraticResponse: è‹æ ¼æ‹‰åº•å¼å›å¤
        """
        # è®¡ç®—å½“å‰è½®æ¬¡
        turn = len([m for m in (conversation_history or []) if (m.get("role") == "user")]) + 1
        
        # æ£€ç´¢ç›¸å…³æ–‡æ¡£å†…å®¹
        chunks = self.retriever.retrieve(
            query=user_input,
            user_id=user_id,
            n_results=5,
            document_ids=document_ids
        )
        
        context = "\n\n".join([
            f"[ç‰‡æ®µ {i+1}]\n{chunk['content']}" 
            for i, chunk in enumerate(chunks)
            if isinstance(chunk, dict) and (chunk.get("content") or "").strip()
        ]) if chunks else "æš‚æ— ç›¸å…³å‚è€ƒèµ„æ–™"
        
        # æ ¼å¼åŒ–å¯¹è¯å†å²
        history = self._format_history(conversation_history)
        
        # æ„å»ºæ¶ˆæ¯
        system_msg = self.SYSTEM_PROMPT.format(context=context)
        user_msg = self.USER_PROMPT.format(
            history=history,
            input=user_input,
            turn=turn
        )
        
        messages = [
            SystemMessage(content=system_msg),
            HumanMessage(content=user_msg)
        ]
        
        # è°ƒç”¨LLM
        llm = self.model_router.get_chat_model(user_id=user_id, module="socratic", streaming=False)
        response = llm.invoke(messages)
        result_raw = self._parse_response(getattr(response, "content", ""))
        result: Dict[str, Any] = result_raw if isinstance(result_raw, dict) else {"question": str(result_raw)}
        
        # æ„å»ºå›å¤æ–‡æœ¬
        reply_parts = []
        if result.get("encouragement"):
            reply_parts.append(result["encouragement"])
        if result.get("bridge"):
            reply_parts.append(result["bridge"])
        
        # æ ¸å¿ƒé—®é¢˜
        question = result.get("question", "ä½ è§‰å¾—è¿™ä¸ªæ¦‚å¿µçš„æ ¸å¿ƒæ˜¯ä»€ä¹ˆï¼Ÿ")
        reply_parts.append(f"\n\n**ğŸ¤” {question}**")
        
        # æç¤ºï¼ˆå¦‚æœæœ‰ï¼‰
        if result.get("hint"):
            reply_parts.append(f"\n\nğŸ’¡ *å°æç¤ºï¼š{result['hint']}*")
        
        full_reply = "\n".join(reply_parts)
        
        # è§£æé˜¶æ®µ
        phase_str = result.get("phase", "exploration")
        try:
            phase = DialoguePhase(phase_str)
        except ValueError:
            phase = DialoguePhase.EXPLORATION

        # progress å½’ä¸€åŒ–
        try:
            progress = float(result.get("progress", 0.3))
        except Exception:
            progress = 0.3
        if progress < 0:
            progress = 0.0
        if progress > 1:
            progress = 1.0
        
        return SocraticResponse(
            question=full_reply,
            hint=result.get("hint"),
            phase=phase,
            encouragement=result.get("encouragement"),
            knowledge_check=turn >= 5,
            related_concepts=[],
            progress=progress
        )
    
    def get_summary(
        self,
        conversation_history: List[Dict],
        user_id: str
    ) -> str:
        """
        ç”Ÿæˆå¯¹è¯æ€»ç»“
        
        Args:
            conversation_history: å®Œæ•´å¯¹è¯å†å²
            user_id: ç”¨æˆ·ID
            
        Returns:
            str: å­¦ä¹ æ€»ç»“
        """
        if len(conversation_history) < 4:
            return "å¯¹è¯è½®æ¬¡è¾ƒå°‘ï¼Œå»ºè®®ç»§ç»­æ·±å…¥æ¢è®¨ä»¥è·å¾—å®Œæ•´æ€»ç»“ã€‚"
        
        history = self._format_history(conversation_history)
        
        summary_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹è‹æ ¼æ‹‰åº•å¼å¯¹è¯ï¼Œæ€»ç»“å­¦ç”Ÿçš„å­¦ä¹ æ”¶è·ï¼š

{history}

è¯·ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„å­¦ä¹ æ€»ç»“ï¼ˆ3-5å¥è¯ï¼‰ï¼ŒåŒ…æ‹¬ï¼š
1. å­¦ç”Ÿæ¢ç´¢çš„æ ¸å¿ƒé—®é¢˜
2. å­¦ç”Ÿé€šè¿‡æ€è€ƒå‘ç°çš„å…³é”®ç‚¹
3. å»ºè®®è¿›ä¸€æ­¥æ¢ç´¢çš„æ–¹å‘

ç”¨ä¸­æ–‡å›å¤ã€‚"""
        
        messages = [HumanMessage(content=summary_prompt)]
        llm = self.model_router.get_chat_model(user_id=user_id, module="socratic", streaming=False)
        response = llm.invoke(messages)
        
        return response.content
